{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f4080c8",
   "metadata": {},
   "source": [
    "# Linear Regression Diagnostics\n",
    "\n",
    "[Resource](https://www.statsmodels.org/dev/examples/notebooks/generated/linear_regression_diagnostics_plots.html)\n",
    "\n",
    "In real-life, relation between response and target variables are seldom linear. Here, we make use of outputs of `statsmodels` to visualize and identify potential problems that can occur from fitting a linear regression model to non-linear relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "077d85d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8584ed",
   "metadata": {},
   "source": [
    "## Simple multiple linear regression\n",
    "\n",
    "Firstly, let's load the advertising data from the ISLR book and fit a linear model (look at that! They're using the same resource as me!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7590c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TV",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Radio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Newspaper",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Sales",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9607be2d-45f1-4668-a7da-d3708ad5841e",
       "rows": [
        [
         "0",
         "230.1",
         "37.8",
         "69.2",
         "22.1"
        ],
        [
         "1",
         "44.5",
         "39.3",
         "45.1",
         "10.4"
        ],
        [
         "2",
         "17.2",
         "45.9",
         "69.3",
         "9.3"
        ],
        [
         "3",
         "151.5",
         "41.3",
         "58.5",
         "18.5"
        ],
        [
         "4",
         "180.8",
         "10.8",
         "58.4",
         "12.9"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = \"https://raw.githubusercontent.com/nguyen-toan/ISLR/07fd968ea484b5f6febc7b392a28eb64329a4945/dataset/Advertising.csv\"\n",
    "df = pd.read_csv(data_url).drop(\"Unnamed: 0\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac8d33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared:         </th> <td>   0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   570.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 02 Nov 2025</td> <th>  Prob (F-statistic):</th> <td>1.58e-96</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:56:02</td>     <th>  Log-Likelihood:    </th> <td> -386.18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   780.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   196</td>      <th>  BIC:               </th> <td>   793.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.9389</td> <td>    0.312</td> <td>    9.422</td> <td> 0.000</td> <td>    2.324</td> <td>    3.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TV</th>        <td>    0.0458</td> <td>    0.001</td> <td>   32.809</td> <td> 0.000</td> <td>    0.043</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Radio</th>     <td>    0.1885</td> <td>    0.009</td> <td>   21.893</td> <td> 0.000</td> <td>    0.172</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Newspaper</th> <td>   -0.0010</td> <td>    0.006</td> <td>   -0.177</td> <td> 0.860</td> <td>   -0.013</td> <td>    0.011</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>60.414</td> <th>  Durbin-Watson:     </th> <td>   2.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 151.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.327</td> <th>  Prob(JB):          </th> <td>1.44e-33</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.332</td> <th>  Cond. No.          </th> <td>    454.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Sales       & \\textbf{  R-squared:         } &     0.897   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.896   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     570.3   \\\\\n",
       "\\textbf{Date:}             & Sun, 02 Nov 2025 & \\textbf{  Prob (F-statistic):} &  1.58e-96   \\\\\n",
       "\\textbf{Time:}             &     08:56:02     & \\textbf{  Log-Likelihood:    } &   -386.18   \\\\\n",
       "\\textbf{No. Observations:} &         200      & \\textbf{  AIC:               } &     780.4   \\\\\n",
       "\\textbf{Df Residuals:}     &         196      & \\textbf{  BIC:               } &     793.6   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &       2.9389  &        0.312     &     9.422  &         0.000        &        2.324    &        3.554     \\\\\n",
       "\\textbf{TV}        &       0.0458  &        0.001     &    32.809  &         0.000        &        0.043    &        0.049     \\\\\n",
       "\\textbf{Radio}     &       0.1885  &        0.009     &    21.893  &         0.000        &        0.172    &        0.206     \\\\\n",
       "\\textbf{Newspaper} &      -0.0010  &        0.006     &    -0.177  &         0.860        &       -0.013    &        0.011     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 60.414 & \\textbf{  Durbin-Watson:     } &    2.084  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &  151.241  \\\\\n",
       "\\textbf{Skew:}          & -1.327 & \\textbf{  Prob(JB):          } & 1.44e-33  \\\\\n",
       "\\textbf{Kurtosis:}      &  6.332 & \\textbf{  Cond. No.          } &     454.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Sales   R-squared:                       0.897\n",
       "Model:                            OLS   Adj. R-squared:                  0.896\n",
       "Method:                 Least Squares   F-statistic:                     570.3\n",
       "Date:                Sun, 02 Nov 2025   Prob (F-statistic):           1.58e-96\n",
       "Time:                        08:56:02   Log-Likelihood:                -386.18\n",
       "No. Observations:                 200   AIC:                             780.4\n",
       "Df Residuals:                     196   BIC:                             793.6\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      2.9389      0.312      9.422      0.000       2.324       3.554\n",
       "TV             0.0458      0.001     32.809      0.000       0.043       0.049\n",
       "Radio          0.1885      0.009     21.893      0.000       0.172       0.206\n",
       "Newspaper     -0.0010      0.006     -0.177      0.860      -0.013       0.011\n",
       "==============================================================================\n",
       "Omnibus:                       60.414   Durbin-Watson:                   2.084\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              151.241\n",
       "Skew:                          -1.327   Prob(JB):                     1.44e-33\n",
       "Kurtosis:                       6.332   Cond. No.                         454.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = smf.ols(formula='Sales ~ TV + Radio + Newspaper', data=df).fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7f34c8",
   "metadata": {},
   "source": [
    "# Diagnostic Figures/Table\n",
    "\n",
    "In the following first we present a base code that we will use later to generate the following diagnostic plots:\n",
    "\n",
    "a. residual\n",
    "\n",
    "b. qq\n",
    "\n",
    "c. scale location\n",
    "\n",
    "d. leverage\n",
    "\n",
    "and a table\n",
    "\n",
    "a. vif\n",
    "\n",
    "(I didn't bother manually typing all of this. Refer to this when needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "723a651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from statsmodels.tools.tools import maybe_unwrap_results\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Type\n",
    "\n",
    "style_talk = \"seaborn-talk\" \n",
    "\n",
    "class LinearRegDiagnostic:\n",
    "    \"\"\"\n",
    "    Diagnostic plots to identify potential problems in a linear regression fit.\n",
    "    Mainly,\n",
    "        a. non-linearity of data\n",
    "        b. Correlation of error terms\n",
    "        c. non-constant variance\n",
    "        d. outliers\n",
    "        e. high-leverage points\n",
    "        f. collinearity\n",
    "\n",
    "    Authors:\n",
    "        Prajwal Kafle (p33ajkafle@gmail.com, where 3 = r)\n",
    "        Does not come with any sort of warranty.\n",
    "        Please test the code one your end before using.\n",
    "\n",
    "        Matt Spinelli (m3spinelli@gmail.com, where 3 = r)\n",
    "        (1) Fixed incorrect annotation of the top most extreme residuals in\n",
    "            the Residuals vs Fitted and, especially, the Normal Q-Q plots.\n",
    "        (2) Changed Residuals vs Leverage plot to match closer the y-axis\n",
    "            range shown in the equivalent plot in the R package ggfortify.\n",
    "        (3) Added horizontal line at y=0 in Residuals vs Leverage plot to\n",
    "            match the plots in R package ggfortify and base R.\n",
    "        (4) Added option for placing a vertical guideline on the Residuals\n",
    "            vs Leverage plot using the rule of thumb of h = 2p/n to denote\n",
    "            high leverage (high_leverage_threshold=True).\n",
    "        (5) Added two more ways to compute the Cook's Distance (D) threshold:\n",
    "            * 'baseR': D > 1 and D > 0.5 (default)\n",
    "            * 'convention': D > 4/n\n",
    "            * 'dof': D > 4 / (n - k - 1)\n",
    "        (6) Fixed class name to conform to Pascal casing convention\n",
    "        (7) Fixed Residuals vs Leverage legend to work with loc='best'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        results: Type[statsmodels.regression.linear_model.RegressionResultsWrapper],\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        For a linear regression model, generates following diagnostic plots:\n",
    "\n",
    "        a. residual\n",
    "        b. qq\n",
    "        c. scale location and\n",
    "        d. leverage\n",
    "\n",
    "        and a table\n",
    "\n",
    "        e. vif\n",
    "\n",
    "        Args:\n",
    "            results (Type[statsmodels.regression.linear_model.RegressionResultsWrapper]):\n",
    "                must be instance of statsmodels.regression.linear_model object\n",
    "\n",
    "        Raises:\n",
    "            TypeError: if instance does not belong to above object\n",
    "\n",
    "        Example:\n",
    "        >>> import numpy as np\n",
    "        >>> import pandas as pd\n",
    "        >>> import statsmodels.formula.api as smf\n",
    "        >>> x = np.linspace(-np.pi, np.pi, 100)\n",
    "        >>> y = 3*x + 8 + np.random.normal(0,1, 100)\n",
    "        >>> df = pd.DataFrame({'x':x, 'y':y})\n",
    "        >>> res = smf.ols(formula= \"y ~ x\", data=df).fit()\n",
    "        >>> cls = Linear_Reg_Diagnostic(res)\n",
    "        >>> cls(plot_context=\"seaborn-v0_8-paper\")\n",
    "\n",
    "        In case you do not need all plots you can also independently make an individual plot/table\n",
    "        in following ways\n",
    "\n",
    "        >>> cls = Linear_Reg_Diagnostic(res)\n",
    "        >>> cls.residual_plot()\n",
    "        >>> cls.qq_plot()\n",
    "        >>> cls.scale_location_plot()\n",
    "        >>> cls.leverage_plot()\n",
    "        >>> cls.vif_table()\n",
    "        \"\"\"\n",
    "\n",
    "        if (\n",
    "            isinstance(\n",
    "                results, statsmodels.regression.linear_model.RegressionResultsWrapper\n",
    "            )\n",
    "            is False\n",
    "        ):\n",
    "            raise TypeError(\n",
    "                \"result must be instance of statsmodels.regression.linear_model.RegressionResultsWrapper object\"\n",
    "            )\n",
    "\n",
    "        self.results = maybe_unwrap_results(results)\n",
    "\n",
    "        self.y_true = self.results.model.endog\n",
    "        self.y_predict = self.results.fittedvalues\n",
    "        self.xvar = self.results.model.exog\n",
    "        self.xvar_names = self.results.model.exog_names\n",
    "\n",
    "        self.residual = np.array(self.results.resid)\n",
    "        influence = self.results.get_influence()\n",
    "        self.residual_norm = influence.resid_studentized_internal\n",
    "        self.leverage = influence.hat_matrix_diag\n",
    "        self.cooks_distance = influence.cooks_distance[0]\n",
    "        self.nparams = len(self.results.params)\n",
    "        self.nresids = len(self.residual_norm)\n",
    "\n",
    "    def __call__(self, plot_context=\"seaborn-v0_8-paper\", **kwargs):\n",
    "        # print(plt.style.available)\n",
    "        # GH#9157\n",
    "        if plot_context not in plt.style.available:\n",
    "            plot_context = \"default\"\n",
    "        with plt.style.context(plot_context):\n",
    "            fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "            self.residual_plot(ax=ax[0, 0])\n",
    "            self.qq_plot(ax=ax[0, 1])\n",
    "            self.scale_location_plot(ax=ax[1, 0])\n",
    "            self.leverage_plot(\n",
    "                ax=ax[1, 1],\n",
    "                high_leverage_threshold=kwargs.get(\"high_leverage_threshold\"),\n",
    "                cooks_threshold=kwargs.get(\"cooks_threshold\"),\n",
    "            )\n",
    "            plt.show()\n",
    "\n",
    "        return (\n",
    "            self.vif_table(),\n",
    "            fig,\n",
    "            ax,\n",
    "        )\n",
    "\n",
    "    def residual_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Residual vs Fitted Plot\n",
    "\n",
    "        Graphical tool to identify non-linearity.\n",
    "        (Roughly) Horizontal red line is an indicator that the residual has a linear pattern\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        sns.residplot(\n",
    "            x=self.y_predict,\n",
    "            y=self.residual,\n",
    "            lowess=True,\n",
    "            scatter_kws={\"alpha\": 0.5},\n",
    "            line_kws={\"color\": \"red\", \"lw\": 1, \"alpha\": 0.8},\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "        # annotations\n",
    "        residual_abs = np.abs(self.residual)\n",
    "        abs_resid = np.flip(np.argsort(residual_abs), 0)\n",
    "        abs_resid_top_3 = abs_resid[:3]\n",
    "        for i in abs_resid_top_3:\n",
    "            ax.annotate(i, xy=(self.y_predict[i], self.residual[i]), color=\"C3\")\n",
    "\n",
    "        ax.set_title(\"Residuals vs Fitted\", fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Fitted values\")\n",
    "        ax.set_ylabel(\"Residuals\")\n",
    "        return ax\n",
    "\n",
    "    def qq_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Standarized Residual vs Theoretical Quantile plot\n",
    "\n",
    "        Used to visually check if residuals are normally distributed.\n",
    "        Points spread along the diagonal line will suggest so.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        QQ = ProbPlot(self.residual_norm)\n",
    "        fig = QQ.qqplot(line=\"45\", alpha=0.5, lw=1, ax=ax)\n",
    "\n",
    "        # annotations\n",
    "        abs_norm_resid = np.flip(np.argsort(np.abs(self.residual_norm)), 0)\n",
    "        abs_norm_resid_top_3 = abs_norm_resid[:3]\n",
    "        for i, x, y in self.__qq_top_resid(\n",
    "            QQ.theoretical_quantiles, abs_norm_resid_top_3\n",
    "        ):\n",
    "            ax.annotate(i, xy=(x, y), ha=\"right\", color=\"C3\")\n",
    "\n",
    "        ax.set_title(\"Normal Q-Q\", fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Theoretical Quantiles\")\n",
    "        ax.set_ylabel(\"Standardized Residuals\")\n",
    "        return ax\n",
    "\n",
    "    def scale_location_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Sqrt(Standarized Residual) vs Fitted values plot\n",
    "\n",
    "        Used to check homoscedasticity of the residuals.\n",
    "        Horizontal line will suggest so.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        residual_norm_abs_sqrt = np.sqrt(np.abs(self.residual_norm))\n",
    "\n",
    "        ax.scatter(self.y_predict, residual_norm_abs_sqrt, alpha=0.5)\n",
    "        sns.regplot(\n",
    "            x=self.y_predict,\n",
    "            y=residual_norm_abs_sqrt,\n",
    "            scatter=False,\n",
    "            ci=False,\n",
    "            lowess=True,\n",
    "            line_kws={\"color\": \"red\", \"lw\": 1, \"alpha\": 0.8},\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "        # annotations\n",
    "        abs_sq_norm_resid = np.flip(np.argsort(residual_norm_abs_sqrt), 0)\n",
    "        abs_sq_norm_resid_top_3 = abs_sq_norm_resid[:3]\n",
    "        for i in abs_sq_norm_resid_top_3:\n",
    "            ax.annotate(\n",
    "                i, xy=(self.y_predict[i], residual_norm_abs_sqrt[i]), color=\"C3\"\n",
    "            )\n",
    "\n",
    "        ax.set_title(\"Scale-Location\", fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Fitted values\")\n",
    "        ax.set_ylabel(r\"$\\sqrt{|\\mathrm{Standardized\\ Residuals}|}$\")\n",
    "        return ax\n",
    "\n",
    "    def leverage_plot(\n",
    "        self, ax=None, high_leverage_threshold=False, cooks_threshold=\"baseR\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Residual vs Leverage plot\n",
    "\n",
    "        Points falling outside Cook's distance curves are considered observation that can sway the fit\n",
    "        aka are influential.\n",
    "        Good to have none outside the curves.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        ax.scatter(self.leverage, self.residual_norm, alpha=0.5)\n",
    "\n",
    "        sns.regplot(\n",
    "            x=self.leverage,\n",
    "            y=self.residual_norm,\n",
    "            scatter=False,\n",
    "            ci=False,\n",
    "            lowess=True,\n",
    "            line_kws={\"color\": \"red\", \"lw\": 1, \"alpha\": 0.8},\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "        # annotations\n",
    "        leverage_top_3 = np.flip(np.argsort(self.cooks_distance), 0)[:3]\n",
    "        for i in leverage_top_3:\n",
    "            ax.annotate(i, xy=(self.leverage[i], self.residual_norm[i]), color=\"C3\")\n",
    "\n",
    "        factors = []\n",
    "        if cooks_threshold == \"baseR\" or cooks_threshold is None:\n",
    "            factors = [1, 0.5]\n",
    "        elif cooks_threshold == \"convention\":\n",
    "            factors = [4 / self.nresids]\n",
    "        elif cooks_threshold == \"dof\":\n",
    "            factors = [4 / (self.nresids - self.nparams)]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"threshold_method must be one of the following: 'convention', 'dof', or 'baseR' (default)\"\n",
    "            )\n",
    "        for i, factor in enumerate(factors):\n",
    "            label = \"Cook's distance\" if i == 0 else None\n",
    "            xtemp, ytemp = self.__cooks_dist_line(factor)\n",
    "            ax.plot(xtemp, ytemp, label=label, lw=1.25, ls=\"--\", color=\"red\")\n",
    "            ax.plot(xtemp, np.negative(ytemp), lw=1.25, ls=\"--\", color=\"red\")\n",
    "\n",
    "        if high_leverage_threshold:\n",
    "            high_leverage = 2 * self.nparams / self.nresids\n",
    "            if max(self.leverage) > high_leverage:\n",
    "                ax.axvline(\n",
    "                    high_leverage, label=\"High leverage\", ls=\"-.\", color=\"purple\", lw=1\n",
    "                )\n",
    "\n",
    "        ax.axhline(0, ls=\"dotted\", color=\"black\", lw=1.25)\n",
    "        ax.set_xlim(0, max(self.leverage) + 0.01)\n",
    "        ax.set_ylim(min(self.residual_norm) - 0.1, max(self.residual_norm) + 0.1)\n",
    "        ax.set_title(\"Residuals vs Leverage\", fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Leverage\")\n",
    "        ax.set_ylabel(\"Standardized Residuals\")\n",
    "        plt.legend(loc=\"best\")\n",
    "        return ax\n",
    "\n",
    "    def vif_table(self):\n",
    "        \"\"\"\n",
    "        VIF table\n",
    "\n",
    "        VIF, the variance inflation factor, is a measure of multicollinearity.\n",
    "        VIF > 5 for a variable indicates that it is highly collinear with the\n",
    "        other input variables.\n",
    "        \"\"\"\n",
    "        vif_df = pd.DataFrame()\n",
    "        vif_df[\"Features\"] = self.xvar_names\n",
    "        vif_df[\"VIF Factor\"] = [\n",
    "            variance_inflation_factor(self.xvar, i) for i in range(self.xvar.shape[1])\n",
    "        ]\n",
    "\n",
    "        return vif_df.sort_values(\"VIF Factor\").round(2)\n",
    "\n",
    "    def __cooks_dist_line(self, factor):\n",
    "        \"\"\"\n",
    "        Helper function for plotting Cook's distance curves\n",
    "        \"\"\"\n",
    "        p = self.nparams\n",
    "        formula = lambda x: np.sqrt((factor * p * (1 - x)) / x)\n",
    "        x = np.linspace(0.001, max(self.leverage), 50)\n",
    "        y = formula(x)\n",
    "        return x, y\n",
    "\n",
    "    def __qq_top_resid(self, quantiles, top_residual_indices):\n",
    "        \"\"\"\n",
    "        Helper generator function yielding the index and coordinates\n",
    "        \"\"\"\n",
    "        offset = 0\n",
    "        quant_index = 0\n",
    "        previous_is_negative = None\n",
    "        for resid_index in top_residual_indices:\n",
    "            y = self.residual_norm[resid_index]\n",
    "            is_negative = y < 0\n",
    "            if previous_is_negative == None or previous_is_negative == is_negative:\n",
    "                offset += 1\n",
    "            else:\n",
    "                quant_index -= offset\n",
    "            x = (\n",
    "                quantiles[quant_index]\n",
    "                if is_negative\n",
    "                else np.flip(quantiles, 0)[quant_index]\n",
    "            )\n",
    "            quant_index += 1\n",
    "            previous_is_negative = is_negative\n",
    "            yield resid_index, x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae2a727",
   "metadata": {},
   "source": [
    "We're just gonna skip this for now and begin an example. Come back here if you need to."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statsmodels-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
